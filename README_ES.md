# ğŸ§  ai-helm-linter

> Microservicio inteligente para auditar Helm Charts usando LLMs (Ollama o OpenAI), detectando errores, inconsistencias o malas prÃ¡cticas mediante prompts especializados.  

Desarrollado en Python + Flask, con CLI integrada y despliegue vÃ­a Helm + ArgoCD.

---

## ğŸš€ CaracterÃ­sticas

- âœ… Audita sintaxis, convenciones y coherencia estructural en Charts Helm  
- ğŸ” Analiza `Chart.yaml`, `values.yaml`, `templates/*`, `*.tpl`, `*.json`, etc.  
- ğŸ¤– Compatible con modelos locales (Ollama) o remotos (GPT-4 vÃ­a OpenAI)  
- ğŸ”„ Fallback automÃ¡tico a OpenAI si Ollama falla  
- ğŸ§© CLI y API REST completas  
- ğŸ³ Dockerizado y desplegable con Helm + ArgoCD  
- ğŸ“ Compatible con entornos GitOps y pipelines CI/CD  
- âœï¸ Prompt modular y editable (`helm_linting.prompt`)  
- ğŸ“¦ Soporta Charts en carpeta o empaquetados `.tgz`  

---

## ğŸ“¦ Estructura del Proyecto

```
ai-helm-linter/
â”œâ”€â”€ app.py                 # Entrada Flask del microservicio
â”œâ”€â”€ cli/                   # CLI para ejecuciÃ³n directa
â”œâ”€â”€ lib/                   # LÃ³gica de negocio y clientes IA
â”œâ”€â”€ prompts/               # Plantillas de prompt
â”œâ”€â”€ routes/                # Rutas API (Blueprint Flask)
â”œâ”€â”€ Dockerfile             # Imagen contenedor
â”œâ”€â”€ Makefile               # Build y despliegue automatizado
â”œâ”€â”€ requirements.txt       # Dependencias Python
â””â”€â”€ README.md              # DocumentaciÃ³n del proyecto
```

---

## ğŸ§© Componentes

### `cli/lint.py`

CLI directa para analizar Charts desde terminal:

```bash
python3 cli/lint.py --mode ollama --chart_path charts/example
```

- `--mode`: `ollama` o `openai`  
- `--chart_path`: ruta a carpeta o `.tgz`  
- `--ruleset`: nombre del ruleset a aplicar (por defecto: `"default"`)

### `app.py` + `routes/lint_chart.py`

Microservicio Flask que expone el endpoint `/lint-chart` para recibir Charts y retornar el anÃ¡lisis IA.

- Entrada esperada:
  - `multipart/form-data` con archivo `.tgz`
  - campos `mode` (`ollama|openai`) y `ruleset` (opcional)
- Salida: JSON con resultado IA interpretado

---

## ğŸ§  LÃ³gica Interna

### `lib/linter.py`

- Carga el prompt base (`helm_linting.prompt`)  
- Inserta el contenido del Chart y las reglas  
- Llama a `query_ollama()` o `query_openai()`  
- Si Ollama falla, hace fallback automÃ¡tico a OpenAI

### `lib/utils.py`

- Carga Charts desde carpeta o `.tgz`
- Recorre `*.yaml`, `*.tpl`, `*.json`, etc., inyectÃ¡ndolos con su path relativo
- Carga plantillas de prompt como texto plano

### `lib/ollama_client.py` y `lib/openai_client.py`

- Realizan peticiones HTTP a Ollama local o GPT-4 remoto  
- Configurables vÃ­a `OLLAMA_BASE_URL` y `OPENAI_API_KEY`  

---

## ğŸ” IntegraciÃ³n Jenkins

```groovy
def jsonPayload = '''
{
  "chart_path": "./charts/mychart.tgz",
  "mode": "ollama"
}
'''

sh """
curl -X POST http://helm-linter.devops-ai.svc.cluster.local:5000/lint-chart \
  -F 'chart=@./charts/mychart.tgz' \
  -F 'mode=ollama' \
  -F 'ruleset=default'
"""
```
---

## ğŸ› ï¸ Primeros pasos (Local)

```bash
git clone https://github.com/dorado-ai-devops/ai-helm-linter.git
cd ai-helm-linter
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Ejecutar CLI

```bash
python3 cli/lint.py --mode ollama --chart_path charts/example
```

### Ejecutar microservicio Flask

```bash
python3 app.py
```

---

## ğŸ’¡ Ejemplo de salida

```
[ERROR] Chart.yaml no contiene el campo "version".
[SUGERENCIA] AÃ±ade una clave "version: 1.0.0" para cumplir con el estÃ¡ndar.
[REVISIÃ“N] La plantilla deployment.yaml fija el puerto 80 de forma rÃ­gida.
```

---

## ğŸ”® PrÃ³ximos pasos

- [ ] Validaciones de seguridad (runAsNonRoot, seccomp, capabilities)
- [ ] Integrar validadores externos (kubeval, kube-score)
- [ ] Exportar JSON estructurado para dashboards Streamlit

---

## ğŸ‘¨â€ğŸ’» Autor

- **Dani** â€“ [@dorado-ai-devops](https://github.com/dorado-ai-devops)

---

## ğŸ§  Inspirado en

- [Buenas prÃ¡cticas Helm](https://helm.sh/docs/chart_best_practices/)
- [Ollama](https://ollama.com)
- [OpenAI API](https://platform.openai.com/docs)

---

## ğŸ›¡ Licencia

Licencia PÃºblica General GNU v3.0
