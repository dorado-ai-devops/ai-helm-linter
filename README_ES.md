# ğŸ§  ai-helm-linter

> Microservicio para auditar Helm Charts con LLMs (OpenAI u Ollama), detectando errores, incoherencias o malas prÃ¡cticas mediante prompts especializados.

---

## ğŸš€ Funcionalidades

- âœ… Audita sintaxis, convenciones y coherencia de Helm Charts
- ğŸ“š Analiza `Chart.yaml`, `values.yaml` y plantillas en `templates/`
- ğŸ¤– Usa modelos locales con Ollama o GPT-4o vÃ­a OpenAI
- ğŸ§© CLI y API REST con Flask integrados
- ğŸ³ Preparado para Docker y despliegue con Helm + ArgoCD
- ğŸ” Fallback automÃ¡tico a OpenAI si Ollama falla
- ğŸ“ Compatible con flujos GitOps y pipelines CI/CD
- âœï¸ Prompts editables para adaptarse a polÃ­ticas personalizadas

---

## ğŸ“¦ Estructura del Proyecto

```
ai-helm-linter/
â”œâ”€â”€ app.py                 # Microservicio Flask (API /lint)
â”œâ”€â”€ cli/                   # Scripts CLI como lint.py
â”œâ”€â”€ lib/                   # Clientes OpenAI/Ollama y lÃ³gica comÃºn
â”œâ”€â”€ charts/                # Charts de ejemplo para pruebas
â”œâ”€â”€ prompts/               # Plantillas .prompt dinÃ¡micas
â”œâ”€â”€ requirements.txt       # Dependencias Python
â”œâ”€â”€ Dockerfile             # Contenedor Flask
â”œâ”€â”€ Makefile               # Build y despliegue automatizado
â””â”€â”€ README.md              # DocumentaciÃ³n del proyecto
```

---

## ğŸ§© DescripciÃ³n Detallada de Componentes

### `app.py`

Microservicio Flask desplegable en K8s:
- Endpoint `/lint`
- Acepta JSON: `{ "chart": "./charts/example", "mode": "openai|ollama" }`
- Carga el contenido del chart
- Llama a `lint.py` y devuelve anÃ¡lisis estructurado

### `cli/lint.py`

Script principal para linting con IA:
- Argumentos: `--mode`, `--chart`
- Carga `Chart.yaml`, `values.yaml`, y plantillas
- Inyecta en prompt dinÃ¡mico
- Devuelve auditorÃ­a tÃ©cnica con explicaciÃ³n

### `lib/`

- `input_loader.py`: lee y organiza los archivos del chart
- `utils.py`: carga plantillas .prompt
- `ollama_client.py`: cliente HTTP para Ollama
- `openai_client.py`: cliente para OpenAI GPT-4o
- `docgen.py`: funciÃ³n core que unifica el anÃ¡lisis

### `prompts/`

- Contiene prompts como `helm_lint.prompt` que pueden modificarse.
- Admite templates para reglas especÃ­ficas de tu organizaciÃ³n.

### `Dockerfile`

Contenedor Flask. Expone puerto 5000.

```bash
docker build -t helm-linter:dev .
docker run -p 5000:5000 helm-linter:dev
```

### `Makefile`

Automatiza tareas como:

```bash
make build             # Build de imagen local
make load              # Carga en KIND
make sync              # Sincroniza con ArgoCD
make release VERSION=v0.1.0
```

---

## ğŸ” Jenkins Integration

Puedes invocar este microservicio desde un pipeline declarativo:

```groovy
def jsonPayload = '''
{
  "chart": "./charts/mychart",
  "mode": "ollama"
}
'''

sh '''
curl -X POST http://helm-linter.devops-ai.svc.cluster.local:5000/lint   -H "Content-Type: application/json"   -d '${jsonPayload}'
'''
```

---

## ğŸ› ï¸ Primeros pasos

```bash
git clone https://github.com/dorado-ai-devops/ai-helm-linter.git
cd ai-helm-linter
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

---

### âš™ï¸ Ejecutar CLI

```bash
python3 cli/lint.py --mode ollama --chart charts/example
```

### âš™ï¸ Ejecutar microservicio

```bash
python3 app.py
```

---

## ğŸ’¡ Ejemplo de salida

```
[ERROR] El archivo Chart.yaml no contiene campo version.
[SUGERENCIA] AÃ±ade una clave "version: 1.0.0" para cumplir el estÃ¡ndar.
[REVISIÃ“N] El template deployment.yaml tiene hardcodeado el puerto 80.
```

---

## ğŸ”® PrÃ³ximos pasos

- AÃ±adir reglas de seguridad (capabilities, runAsUser, etc)
- IntegraciÃ³n con validadores YAML y kubeval
- ExportaciÃ³n a JSON estructurado para dashboards

---

## ğŸ‘¨â€ğŸ’» Autor

- **Dani** â€“ [@dorado-ai-devops](https://github.com/dorado-ai-devops)

---

## ğŸ§  Inspirado por

- [Helm Best Practices](https://helm.sh/docs/chart_best_practices/)
- [Ollama](https://ollama.com)
- [OpenAI API](https://platform.openai.com/docs)

---

## ğŸ›¡ Licencia

Licencia PÃºblica General GNU v3.0