# ğŸ§  ai-helm-linter

> Smart microservice for auditing Helm Charts using LLMs (Ollama or OpenAI), detecting errors, inconsistencies, or bad practices through specialized prompts.  

Built with Python + Flask, with CLI integration and deployable via Helm + ArgoCD.

---

## ğŸš€ Features

- âœ… Audits syntax, conventions, and structural consistency in Helm Charts  
- ğŸ” Analyzes `Chart.yaml`, `values.yaml`, `templates/*`, `*.tpl`, `*.json`, etc.  
- ğŸ¤– Supports local models (Ollama) or remote (GPT-4 via OpenAI)  
- ğŸ”„ Automatic fallback to OpenAI if Ollama fails  
- ğŸ§© Full CLI and REST API  
- ğŸ³ Dockerized and deployable via Helm + ArgoCD  
- ğŸ“ Compatible with GitOps environments and CI/CD pipelines  
- âœï¸ Modular and editable prompt (`helm_linting.prompt`)  
- ğŸ“¦ Supports folders or packaged `.tgz` Helm Charts  

---

## ğŸ“¦ Project Structure

```
ai-helm-linter/
â”œâ”€â”€ app.py                 # Flask microservice entrypoint
â”œâ”€â”€ cli/                   # CLI interface
â”œâ”€â”€ lib/                   # Core logic and AI clients
â”œâ”€â”€ prompts/               # Prompt templates
â”œâ”€â”€ routes/                # Flask API routes
â”œâ”€â”€ Dockerfile             # Container image
â”œâ”€â”€ Makefile               # Build and deploy automation
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Project documentation
```

---

## ğŸ§© Components

### `cli/lint.py`

CLI for analyzing Helm Charts from the terminal:

```bash
python3 cli/lint.py --mode ollama --chart_path charts/example
```

- `--mode`: `ollama` or `openai`  
- `--chart_path`: folder or `.tgz` file  
- `--ruleset`: ruleset to apply (default: `"default"`)

### `app.py` + `routes/lint_chart.py`

Flask microservice exposing `/lint-chart` endpoint for uploading Charts and returning the AI analysis.

- Expected input:
  - `multipart/form-data` with `.tgz` file
  - fields `mode` (`ollama|openai`) and `ruleset` (optional)
- Output: AI-generated analysis in JSON

---

## ğŸ§  Internal Logic

### `lib/linter.py`

- Loads the base prompt (`helm_linting.prompt`)  
- Injects chart contents and selected rules  
- Calls `query_ollama()` or `query_openai()`  
- Falls back to OpenAI if Ollama fails

### `lib/utils.py`

- Loads Charts from folder or `.tgz`
- Scans `*.yaml`, `*.tpl`, `*.json`, etc. and includes relative paths
- Loads prompt templates as plain text

### `lib/ollama_client.py` & `lib/openai_client.py`

- Send HTTP requests to local Ollama or OpenAI's GPT-4  
- Configurable via `OLLAMA_BASE_URL` and `OPENAI_API_KEY`  

---

## ğŸ” Jenkins Integration

```groovy
def jsonPayload = '''
{
  "chart_path": "./charts/mychart.tgz",
  "mode": "ollama"
}
'''

sh """
curl -X POST http://helm-linter.devops-ai.svc.cluster.local:5000/lint-chart \
  -F 'chart=@./charts/mychart.tgz' \
  -F 'mode=ollama' \
  -F 'ruleset=default'
"""
```

---

## ğŸ› ï¸ Getting Started (Local)

```bash
git clone https://github.com/dorado-ai-devops/ai-helm-linter.git
cd ai-helm-linter
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Run CLI

```bash
python3 cli/lint.py --mode ollama --chart_path charts/example
```

### Run Flask microservice

```bash
python3 app.py
```

---

## ğŸ’¡ Sample Output

```
[ERROR] Chart.yaml is missing the "version" field.
[SUGGESTION] Add a "version: 1.0.0" key to comply with standards.
[REVIEW] deployment.yaml hardcodes port 80.
```

---

## ğŸ‘¨â€ğŸ’» Author

- **Dani** â€“ [@dorado-ai-devops](https://github.com/dorado-ai-devops)

---

## ğŸ§  Inspired by

- [Helm Chart Best Practices](https://helm.sh/docs/chart_best_practices/)
- [Ollama](https://ollama.com)
- [OpenAI API](https://platform.openai.com/docs)

---

## ğŸ›¡ License

GNU General Public License v3.0
